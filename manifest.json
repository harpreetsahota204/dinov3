{
    "name": "DINOv3",
    "url": "https://github.com/AdonaiVera/dinov3",
    "models": [
        {
            "base_name": "facebook/dinov3-vits16-pretrain-lvd1689m",
            "base_filename": "dinov3-vits16-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vit7b16-pretrain-lvd1689m",
            "description": "DINOv3 ViT-S/16 model (21M parameters) - Small vision transformer for fast inference",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-vits16plus-pretrain-lvd1689m",
            "base_filename": "dinov3-vits16plus-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vits16plus-pretrain-lvd1689m",
            "description": "DINOv3 ViT-S+/16 model (29M parameters) - Small+ vision transformer with SwiGLU FFN",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction",
                "swiglu"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-vitb16-pretrain-lvd1689m",
            "base_filename": "dinov3-vitb16-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vitb16-pretrain-lvd1689m",
            "description": "DINOv3 ViT-B/16 model (86M parameters) - Base vision transformer, balanced performance",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction",
                "balanced"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-vitl16-pretrain-lvd1689m",
            "base_filename": "dinov3-vitl16-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vitl16-pretrain-lvd1689m",
            "description": "DINOv3 ViT-L/16 model (300M parameters) - Large vision transformer for high accuracy",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction",
                "high-accuracy"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-vith16plus-pretrain-lvd1689m",
            "base_filename": "dinov3-vith16plus-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vith16plus-pretrain-lvd1689m",
            "description": "DINOv3 ViT-H+/16 model (840M parameters) - Huge+ vision transformer with SwiGLU FFN",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction",
                "huge",
                "swiglu"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-vit7b16-pretrain-lvd1689m",
            "base_filename": "dinov3-vit7b16-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vit7b16-pretrain-lvd1689m",
            "description": "DINOv3 ViT-7B/16 model (7.16B parameters) - Giant vision transformer for maximum performance",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction",
                "giant",
                "maximum-performance"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": false
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-convnext-tiny-pretrain-lvd1689m",
            "base_filename": "dinov3-convnext-tiny-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-convnext-tiny-pretrain-lvd1689m",
            "description": "DINOv3 ConvNeXt-Tiny model (29M parameters) - Tiny ConvNeXt for fast inference",
            "tags": [
                "embeddings",
                "convnext",
                "self-supervised",
                "image-feature-extraction"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-convnext-small-pretrain-lvd1689m",
            "base_filename": "dinov3-convnext-small-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-convnext-small-pretrain-lvd1689m",
            "description": "DINOv3 ConvNeXt-Small model (50M parameters) - Small ConvNeXt for balanced performance",
            "tags": [
                "embeddings",
                "convnext",
                "self-supervised",
                "image-feature-extraction",
                "balanced"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-convnext-base-pretrain-lvd1689m",
            "base_filename": "dinov3-convnext-base-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-convnext-base-pretrain-lvd1689m",
            "description": "DINOv3 ConvNeXt-Base model (89M parameters) - Base ConvNeXt for good performance",
            "tags": [
                "embeddings",
                "convnext",
                "self-supervised",
                "image-feature-extraction",
                "good-performance"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-convnext-large-pretrain-lvd1689m",
            "base_filename": "dinov3-convnext-large-pretrain-lvd1689m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-convnext-large-pretrain-lvd1689m",
            "description": "DINOv3 ConvNeXt-Large model (198M parameters) - Large ConvNeXt for high accuracy",
            "tags": [
                "embeddings",
                "convnext",
                "self-supervised",
                "image-feature-extraction",
                "high-accuracy"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-vitl16-pretrain-sat493m",
            "base_filename": "dinov3-vitl16-pretrain-sat493m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vitl16-pretrain-sat493m",
            "description": "DINOv3 ViT-L/16 model (300M parameters) - Large vision transformer trained on satellite data",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction",
                "satellite",
                "geospatial"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": true
                },
                "gpu": {
                    "support": true
                }
            }
        },
        {
            "base_name": "facebook/dinov3-vit7b16-pretrain-sat493m",
            "base_filename": "dinov3-vit7b16-pretrain-sat493m",
            "author": "Meta AI",
            "license": "DINOv3 License",
            "source": "https://huggingface.co/facebook/dinov3-vit7b16-pretrain-sat493m",
            "description": "DINOv3 ViT-7B/16 model (7.16B parameters) - Giant vision transformer trained on satellite data",
            "tags": [
                "embeddings",
                "vision-transformer",
                "self-supervised",
                "image-feature-extraction",
                "giant",
                "satellite",
                "geospatial",
                "maximum-performance"
            ],
            "date_added": "2025-08-14",
            "requirements": {
                "packages": ["torch", "torchvision", "transformers"],
                "cpu": {
                    "support": false
                },
                "gpu": {
                    "support": true
                }
            }
        }
    ]
}